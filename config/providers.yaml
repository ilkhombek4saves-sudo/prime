version: 1
providers:
- name: glm_default
  type: GLM
  api_key: ${ZAI_API_KEY}
  api_base: https://api.z.ai/api/paas/v4
  default_model: glm-4.7
  models:
    glm-4.7:
      max_tokens: 8192
      cost_per_1m_input: 0.6
      cost_per_1m_output: 2.2
  thinking_enabled: true
  rate_limits:
    rpm: 120
    tpm: 200000
  active: true

- name: openai_default
  type: OpenAI
  api_key: ${OPENAI_API_KEY}
  api_base: https://api.openai.com/v1/
  default_model: gpt-4o
  models:
    gpt-4o:
      max_tokens: 4096
      cost_per_1k_input: 0.01
      cost_per_1k_output: 0.03
    gpt-4o-mini:
      max_tokens: 4096
      cost_per_1k_input: 0.00015
      cost_per_1k_output: 0.0006
  token_optimization:
    auto_route_enabled: true
    route_by_complexity:
      simple: gpt-4o-mini
      complex: gpt-4o
    input_budget_tokens: 6000
    max_output_tokens: 1024
    max_message_tokens: 1200
    output_to_input_ratio: 1.8
  thinking_enabled: false
  rate_limits:
    rpm: 300
    tpm: 120000
  active: true

- name: deepseek_default
  type: DeepSeek
  api_key: ${DEEPSEEK_API_KEY}
  api_base: https://api.deepseek.com/v1/
  default_model: deepseek-chat
  models:
    deepseek-chat:
      max_tokens: 4096
      cost_per_1m_input: 0.2
      cost_per_1m_output: 0.8
  thinking_enabled: false
  rate_limits:
    rpm: 300
    tpm: 120000
  active: true

- name: kimi_default
  type: Kimi
  api_key: ${KIMI_API_KEY}
  api_base: https://api.moonshot.cn/v1/
  default_model: kimi-k2
  models:
    kimi-k2:
      max_tokens: 4096
      cost_per_1m_input: 0.6
      cost_per_1m_output: 2.0
  thinking_enabled: false
  rate_limits:
    rpm: 300
    tpm: 120000
  active: true

- name: ollama_default
  type: Ollama
  # For Docker deployments, use host.docker.internal (see docker-compose extra_hosts).
  api_base: ${OLLAMA_API_BASE:-http://host.docker.internal:11434/v1}
  default_model: ${OLLAMA_MODEL:-llama3.2}
  models:
    llama3.2:
      max_tokens: 4096
      cost_per_1m_input: 0.0
      cost_per_1m_output: 0.0
  thinking_enabled: false
  active: true

- name: shell_default
  type: Shell
  allowed_scripts: [deploy.sh, test.sh, backup.sh]
  models:
    shell-local:
      max_tokens: 0
  humanization:
    enabled: true
    think_delay_min_ms: 120
    think_delay_max_ms: 520
    max_total_delay_ms: 1200
    chunk_chars_min: 12
    chunk_chars_max: 30
  active: true
